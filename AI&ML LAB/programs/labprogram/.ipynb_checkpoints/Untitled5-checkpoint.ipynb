{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcac657-0575-46de-988d-d3dfd55431c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Getting the data from the csv\n",
    "df = pd.read_csv('breast_cancer.csv')\n",
    "X = df[['Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion',\n",
    "        'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses']].to_numpy()\n",
    "\n",
    "# Normalizing the data\n",
    "mu = X.mean(axis=0)\n",
    "sigma = X.std(axis=0)\n",
    "X = (X - mu) / sigma\n",
    "Y = df['Class'].to_numpy()\n",
    "Y = Y / 2 - 1\n",
    "\n",
    "# Initializing the weights and bias\n",
    "global w_in, b_in\n",
    "w_in = np.zeros_like(X[0])\n",
    "b_in = 0.0\n",
    "\n",
    "# Hyperparams\n",
    "learning_rate = 0.001\n",
    "iterations = 1000\n",
    "regularization = 0.5\n",
    "folds = 10\n",
    "\n",
    "\n",
    "def model(x, w, b):\n",
    "    z = np.dot(x, w) + b\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def cost(x, y, w, b, lambda_):\n",
    "    m, n = x.shape\n",
    "    c = 0.0\n",
    "    for i in range(m):\n",
    "        f_wb_i = model(x[i], w, b)\n",
    "        c += (-y[i] * np.log(f_wb_i)) - ((1 - y[i]) * np.log(1 - f_wb_i))\n",
    "    reg_cost = 0\n",
    "    for j in range(n):\n",
    "        reg_cost += w[j] ** 2\n",
    "\n",
    "    return c / m + (lambda_ / (2 * m)) * reg_cost\n",
    "\n",
    "\n",
    "def gradient(x, y, w, b, lambda_):\n",
    "    m, n = x.shape\n",
    "    dj_dw = np.zeros(n, )\n",
    "    dj_db = 0\n",
    "    for i in range(m):\n",
    "        err = model(x[i], w, b) - y[i]\n",
    "        dj_db += err\n",
    "        for j in range(n):\n",
    "            dj_dw_aux = err * x[i, j]\n",
    "            dj_dw[j] += dj_dw_aux\n",
    "    dj_dw /= m\n",
    "    dj_db /= m\n",
    "    for j in range(n):\n",
    "        dj_dw[j] += (lambda_ / m) * w[j]\n",
    "    return dj_db, dj_dw\n",
    "\n",
    "\n",
    "def gradient_descent(x, y, w, b, alpha, iters, lambda_):\n",
    "    J_wb = []\n",
    "    w_aux = copy.deepcopy(w)\n",
    "    b_aux = b\n",
    "    for i in range(iters):\n",
    "        dj_db, dj_dw = gradient(x, y, w_aux, b_aux, lambda_)\n",
    "        w_aux = w_aux - alpha * dj_dw\n",
    "        b_aux = b_aux - alpha * dj_db\n",
    "        if i < 100000:  # prevent resource exhaustion\n",
    "            J_wb.append(cost(x, y, w_aux, b_aux, lambda_))\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i % math.ceil(iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_wb[-1]}   \")\n",
    "    return w_aux, b_aux, J_wb\n",
    "\n",
    "\n",
    "def predict(x, w, b):\n",
    "    m, n = x.shape\n",
    "    p = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        f_wb = model(x[i], w, b)\n",
    "        if f_wb >= 0.5:\n",
    "            p[i] = 1\n",
    "        else:\n",
    "            p[i] = 0\n",
    "    return p\n",
    "\n",
    "\n",
    "def cross_validate(x, y, k, lrate, iters, reg):\n",
    "    n_samples = x.shape[0]\n",
    "    fold_size = n_samples // k\n",
    "    accuracies = []\n",
    "    cost_history = []\n",
    "    for i in range(k):\n",
    "        x_test = x[i * fold_size:(i + 1) * fold_size, :]\n",
    "        y_test = y[i * fold_size:(i + 1) * fold_size]\n",
    "        x_train = np.concatenate((x[:i * fold_size, :], x[(i + 1) * fold_size:, :]), axis=0)\n",
    "        y_train = np.concatenate((y[:i * fold_size], y[(i + 1) * fold_size:]), axis=0)\n",
    "        w_out, b_out, J_wb = gradient_descent(x_train, y_train, w_in, b_in, lrate, iters, reg)\n",
    "        pr = predict(x_test, w_out, b_out)\n",
    "        accuracy = np.mean(pr == y_test) * 100\n",
    "        accuracies.append(accuracy)\n",
    "        cost_history.append(J_wb)\n",
    "    return accuracies, cost_history\n",
    "\n",
    "\n",
    "accuracies, cost_history = cross_validate(X, Y, folds, learning_rate, iterations, regularization)\n",
    "\n",
    "# Plotting the cost function over iterations for each fold\n",
    "for i, J_wb in enumerate(cost_history):\n",
    "    plt.plot(range(len(J_wb)), J_wb, label=f'Fold {i+1}')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Cost Function over Iterations for Each Fold')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting the accuracies for each fold\n",
    "plt.plot(range(1, folds + 1), accuracies, marker='o')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy for Each Fold')\n",
    "plt.ylim(0, 100)\n",
    "plt.show()\n",
    "\n",
    "print('Train Accuracy: ', np.mean(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3fb26f8-5dde-4632-a512-ac0875f4c30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "\n",
      "Accuracy: 0.75\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81        99\n",
      "           1       0.65      0.67      0.66        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.74      0.73       154\n",
      "weighted avg       0.76      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/plotly/datasets/master/diabetes.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Information:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['Outcome'])\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
